{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "B5dHnbZm6W8z"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xrjrWI3VzThP",
    "outputId": "b8048055-1ebb-4806-e967-b2462fb1dcba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders in 'Bone_Fracture_Binary_Classification': ['test', 'train', 'val']\n",
      "Files in 'train': ['fractured', 'not fractured']\n",
      "Files in 'val': ['fractured', 'not fractured']\n",
      "Files in 'test': ['fractured', 'not fractured']\n"
     ]
    }
   ],
   "source": [
    "# Read Folders\n",
    "folder_path = 'Bone_Fracture_Binary_Classification'\n",
    "print(\"Folders in 'Bone_Fracture_Binary_Classification':\", os.listdir(folder_path))\n",
    "\n",
    "subfolder_path_train = os.path.join(folder_path, 'train')\n",
    "subfolder_path_val = os.path.join(folder_path, 'val')\n",
    "subfolder_path_test = os.path.join(folder_path, 'test')\n",
    "\n",
    "print(\"Files in 'train':\", os.listdir(subfolder_path_train))\n",
    "print(\"Files in 'val':\", os.listdir(subfolder_path_val))\n",
    "print(\"Files in 'test':\", os.listdir(subfolder_path_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Qqn8et1fucr5"
   },
   "outputs": [],
   "source": [
    "#Preprocessing Functions\n",
    "def preprocess_image(img):\n",
    "\n",
    "    # Step 1: Convert to gray For SIFT\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Step 2: Resize Images\n",
    "    resized = cv2.resize(gray, (224, 224))\n",
    "\n",
    "    # Step 3: Image Enhancement using CLAHE ()\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    enhanced = clahe.apply(resized)\n",
    "\n",
    "    # Step 4: Using Gaussian Blur to remove Noise\n",
    "    denoised = cv2.GaussianBlur(enhanced, (3, 3), 0)\n",
    "\n",
    "    return denoised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KTBSzO2GucpX"
   },
   "outputs": [],
   "source": [
    "# Apply Preprocessing on data\n",
    "\n",
    "def load_and_preprocess_images(folder_path):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for class_name in ['fractured', 'not fractured']:\n",
    "        class_path = os.path.join(folder_path, class_name)\n",
    "        label = 1 if class_name == 'fractured' else 0\n",
    "\n",
    "        for filename in os.listdir(class_path):\n",
    "            if filename.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
    "                img_path = os.path.join(class_path, filename)\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is not None:\n",
    "                    processed_img = preprocess_image(img)\n",
    "                    images.append(processed_img)\n",
    "                    labels.append(label)\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "bYR7g9a0ucoI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (9243, 224, 224), Labels: (9243,)\n",
      "Val set:   (829, 224, 224), Labels: (829,)\n",
      "Test set:  (506, 224, 224), Labels: (506,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = load_and_preprocess_images(os.path.join(folder_path, 'train'))\n",
    "X_val, y_val     = load_and_preprocess_images(os.path.join(folder_path, 'val'))\n",
    "X_test, y_test   = load_and_preprocess_images(os.path.join(folder_path, 'test'))\n",
    "\n",
    "print(f\"Train set: {X_train.shape}, Labels: {y_train.shape}\")\n",
    "print(f\"Val set:   {X_val.shape}, Labels: {y_val.shape}\")\n",
    "print(f\"Test set:  {X_test.shape}, Labels: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "DqQcmdiuucfb"
   },
   "outputs": [],
   "source": [
    "# SIFT Feature Extraction\n",
    "\n",
    "def extract_sift_features(folder_path):\n",
    "    sift = cv2.SIFT_create()\n",
    "    features = {}\n",
    "\n",
    "    for label in os.listdir(folder_path):\n",
    "        label_path = os.path.join(folder_path, label)\n",
    "\n",
    "        if not os.path.isdir(label_path):\n",
    "            print(f\"Skipping {label_path}\")\n",
    "            continue\n",
    "\n",
    "        features[label] = {}\n",
    "\n",
    "        for img_name in os.listdir(label_path):\n",
    "            img_path = os.path.join(label_path, img_name)\n",
    "\n",
    "            try:\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    continue  # Skip this image if it cannot be read\n",
    "\n",
    "                preprocessed = preprocess_image(img)\n",
    "                keypoints, descriptors = sift.detectAndCompute(preprocessed, None)\n",
    "\n",
    "                features[label][img_name] = {\n",
    "                    \"Keypoints Numbers\": len(keypoints),\n",
    "                    \"Descriptors Shape\": descriptors.shape if descriptors is not None else (0, 0)\n",
    "                }\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process image: {img_path} â€” {e}\")\n",
    "                continue\n",
    "\n",
    "    print(\"SIFT feature extraction completed.\")\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "2rVqpn7g_JAk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIFT feature extraction completed.\n",
      "SIFT feature extraction completed.\n",
      "SIFT feature extraction completed.\n"
     ]
    }
   ],
   "source": [
    "# Aplly SIFT Features Extraction on Data\n",
    "features = extract_sift_features(\"Bone_Fracture_Binary_Classification/train\")\n",
    "features = extract_sift_features(\"Bone_Fracture_Binary_Classification/test\")\n",
    "features = extract_sift_features(\"Bone_Fracture_Binary_Classification/val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total extracted descriptors: (1399195, 128)\n"
     ]
    }
   ],
   "source": [
    "def extract_all_sift_descriptors(folder_path):\n",
    "    sift = cv2.SIFT_create()\n",
    "    all_descriptors = []\n",
    "\n",
    "    for label in os.listdir(folder_path):\n",
    "        label_path = os.path.join(folder_path, label)\n",
    "\n",
    "        if not os.path.isdir(label_path):\n",
    "            continue\n",
    "\n",
    "        for img_name in os.listdir(label_path):\n",
    "            img_path = os.path.join(label_path, img_name)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "\n",
    "            preprocessed = preprocess_image(img)\n",
    "            _, descriptors = sift.detectAndCompute(preprocessed, None)\n",
    "            if descriptors is not None:\n",
    "                all_descriptors.extend(descriptors)\n",
    "\n",
    "    return np.array(all_descriptors)\n",
    "\n",
    "# Extract descriptors from training images\n",
    "all_descriptors = extract_all_sift_descriptors(subfolder_path_train)\n",
    "print(\"Total extracted descriptors:\", all_descriptors.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visual vocabulary shape: (100, 128)\n"
     ]
    }
   ],
   "source": [
    "K = 100  \n",
    "kmeans = KMeans(n_clusters=K, random_state=42)\n",
    "kmeans.fit(all_descriptors)\n",
    "\n",
    "visual_words = kmeans.cluster_centers_\n",
    "print(\"Visual vocabulary shape:\", visual_words.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bow_histogram(img, sift, kmeans):\n",
    "    preprocessed = preprocess_image(img)\n",
    "    _, descriptors = sift.detectAndCompute(preprocessed, None)\n",
    "\n",
    "    if descriptors is None:\n",
    "        return np.zeros(K)  # Empty histogram\n",
    "\n",
    "    labels = kmeans.predict(descriptors)\n",
    "    hist = np.bincount(labels, minlength=K)\n",
    "\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bow_features(folder_path):\n",
    "    sift = cv2.SIFT_create()\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for class_name in ['fractured', 'not fractured']:\n",
    "        class_path = os.path.join(folder_path, class_name)\n",
    "        label = 1 if class_name == 'fractured' else 0\n",
    "\n",
    "        for img_name in os.listdir(class_path):\n",
    "            img_path = os.path.join(class_path, img_name)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "\n",
    "            hist = compute_bow_histogram(img, sift, kmeans)\n",
    "            X.append(hist)\n",
    "            y.append(label)\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Train Set: (9243, 100), Labels: (9243,)\n",
      "BoW Validation Set: (829, 100), Labels: (829,)\n",
      "BoW Test Set: (506, 100), Labels: (506,)\n"
     ]
    }
   ],
   "source": [
    "# Convert images to BoW histograms\n",
    "x_train, y_train = extract_bow_features(subfolder_path_train)\n",
    "x_val, y_val = extract_bow_features(subfolder_path_val)\n",
    "x_test, y_test = extract_bow_features(subfolder_path_test)\n",
    "\n",
    "print(f\"BoW Train Set: {x_train.shape}, Labels: {y_train.shape}\")\n",
    "print(f\"BoW Validation Set: {x_val.shape}, Labels: {y_val.shape}\")\n",
    "print(f\"BoW Test Set: {x_test.shape}, Labels: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(x_train, y_train)\n",
    "\n",
    "y_val_pred = svc.predict(x_val)\n",
    "y_pred = svc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.9360675512665863\n",
      "Test Accuracy:  0.950592885375494\n"
     ]
    }
   ],
   "source": [
    "# Evaluate accuracy\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation Accuracy: \", val_accuracy)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Confusion Matrix: \n",
      "[[474  18]\n",
      " [ 35 302]]\n",
      "\n",
      "Test Confusion Matrix: \n",
      "[[250  18]\n",
      " [  7 231]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(f'Validation Confusion Matrix: \\n{confusion_matrix(y_val, y_val_pred)}\\n')\n",
    "print(f'Test Confusion Matrix: \\n{confusion_matrix(y_test, y_pred)}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
